{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, BatchNormalization, Dense, Flatten, Dropout, InputLayer, Input\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from visualizations.evaluation import plot_confusion_matrix, plot_classification_metric_summary\n",
    "from evaluation.model_evaluation import get_classification_metric_summary\n",
    "from models.convolutional_neural_networks.cnn import get_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "\n",
    "\n",
    "cnn_model = get_cnn_model()\n",
    "cnn_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()\n",
    "\n",
    "\n",
    "# Lists to store training and validation loss values\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    history = cnn_model.fit(x_train, y_train, batch_size=1000, epochs=1, validation_split=0.2, verbose=2)\n",
    "\n",
    "    # Append training and validation loss to the lists\n",
    "    train_loss_list.append(history.history['loss'][0])\n",
    "    val_loss_list.append(history.history['val_loss'][0])\n",
    "\n",
    "# Plot Training-Validation curve\n",
    "plt.plot(range(1, 11), train_loss_list, label='Training Loss')\n",
    "plt.plot(range(1, 11), val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training-Validation Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_class = cnn_model.predict(x_test)\n",
    "y_test_pred_class = np.argmax(y_test_pred_class, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_confusion_matrix(y_test, y_test_pred_class,\"Confusion matrix for MNIST dataset using CNNs\" )\n",
    "\n",
    "class_metrics, accuracy = get_classification_metric_summary(y_test, y_test_pred_class)\n",
    "plot_classification_metric_summary(class_metrics, f\"MNIST Class Classification Metrics for Test Set (MLP) (Accuracy = {accuracy:.2f}) \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
